<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Capstone Project | Orion North</title>
  <link href="https://fonts.googleapis.com/css2?family=Orbitron&family=Roboto&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
  <header>
    <h1>Orion North</h1>
    <nav>
      <ul>
        <li><a href="index.html">Home</a></li>
        <li><a href="projects.html">Projects</a></li>
        <li><a href="#contact">Contact</a></li>
      </ul>
    </nav>
  </header>

  <!-- Capstone project details -->
  <section id="capstone-content">
    <h2>Capstone Project: Aegis</h2>
    <div class="capstone-image">
      <img src="assets/aegis.png" alt="Aegis Project">
    </div>
    <div class="capstone-details">
      <p><strong>Overview:</strong> Aegis is my solo STEM capstone project—a real-time, auto-aiming turret powered by computer vision and object detection. It uses a Raspberry Pi 5 with a Hailo AI accelerator for fast YOLO-based tracking and a Pi 3B for motor control. This isn’t some toy—it’s an intelligent autonomous targeting system.</p>
      <p><strong>Technical Details:</strong> The turret uses a PiCam v3 at 480p 120FPS for low-latency visuals, with motor control handled by salvaged stepper motors from a dead 3D printer. Python and OpenCV drive the CV stack, with the option to offload inference to an RTX 3060 during testing. All wrapped in a rotating rig designed for full-range movement, using existing bearings and custom wiring.</p>
      <p><strong>Repository:</strong> <a href="https://github.com/Orion-North/Aegis" target="_blank">View on GitHub</a></p>
    </div>
    <div class="capstone-back">
      <a href="projects.html">← Back to Projects</a>
    </div>
  </section>

  <footer>
    <p>&copy; 2025 Orion North. All rights reserved.</p>
  </footer>
</body>
</html>
